<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="yes" name="apple-touch-fullscreen"><meta content="telephone=no,email=no" name="format-detection"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no"><link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon"><link href="https://fonts.googleapis.com/css?family=Rubik" rel="stylesheet"><script src="https://use.fontawesome.com/adaf0e149c.js"></script><link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.6.0/styles/monokai_sublime.min.css"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/css/post.css"><link rel="stylesheet" href="/css/markdown-github.css"><title>Lotussecret</title><script src="/js/googleAnalytics.js"></script></head><body><div id="postContainer"><div id="postTop"><h4 id="logo">Lotussecret</h4><br><br><h2 id="postTitle">EM算法-笔记</h2><br><span aria-hidden="true" class="postTime fa fa-calendar">2019-2-15</span><br><br></div><section id="articleDiv"><p></p><h3 id="EM算法解决的问题"><a href="#EM算法解决的问题" class="headerlink" title="EM算法解决的问题"></a>EM算法解决的问题</h3><p>当求解模型参数时，若数据中有未观察到的隐含数据Z，则无法直接使用极大似然估计求解。EM（Expectation-Maximization）算法就能用来求解类似的问题。</p><p></p>
<p></p><h3 id="EM算法推导过程"><a href="#EM算法推导过程" class="headerlink" title="EM算法推导过程"></a>EM算法推导过程</h3><p>对于m个样本观察数据x，找出样本的模型参数极大化模型分布的对数似然估计如下：<br>$$<br>\theta = arg \max \limits_{\theta}\sum\limits_{i=1}^m logP(x^{(i)};\theta)<br>$$<br>如果还有未观察到的未知分布数据Z，此时对数似然估计如下：<br>$$<br>\theta = arg \max \limits_{\theta}\sum\limits_{i=1}^m logP(x^{(i)};\theta) = arg \max \limits_{\theta}\sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}P(x^{(i)}， z^{(i)};\theta)<br>$$<br>此时明显无法直接求出theta，设Z的分布为：<br>$$<br>Q_i(z^{(i)})<br>$$<br>上式可缩放如下：<br>$$<br>\begin{align} \sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}P(x^{(i)}， z^{(i)};\theta)   &amp; = \sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}Q_i(z^{(i)})\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}(1) \ &amp; \geq  \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}(2) \end{align}<br>$$<br>式(1)到式(2)主要过程：</p><p></p>
<ul><br><li><p>根据lazy Statistician规则（其中pk为g(x)的分布）：<br>$$<br>E(y) = E|g(x)| = \sum_{k=1}^{\infty }g(x_k)p_k<br>$$</p><br></li><br><li><p>式(1)可以化为：</p><br></li><br></ul><br><p>$$<br>\sum\limits_{i=1}^m log\sum\limits_{z^{(i)}}Q_i(z^{(i)})\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})} = \sum\limits_{i=1}^m logE(\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})})(3)<br>$$</p><br><ul><br><li>根据Jensen不等式：<br>$$<br>f(E(x)) \geq E(f(x))\;\; 如果f(x) 是凹函数<br>$$<br>​</li><br></ul><br><p>$$<br>\sum\limits_{i=1}^m logE(\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}) \geq \sum\limits_{i=1}^m E(log\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})})<br>$$</p><br><ul><br><li>由因lazy Statistician规则：<br>$$<br>\sum\limits_{i=1}^m E(log\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}) = \sum\limits_{i=1}^m \sum\limits_{z^{(i)}}Q_i(z^{(i)})log\frac{P(x^{(i)}， z^{(i)};\theta)}{Q_i(z^{(i)})}<br>$$<br>​</li><br></ul>
</section></div><script src="/js/jquery.min.js"></script><script src="/js/highlight.min.js"></script><script src="/js/start.js"></script></body></html>